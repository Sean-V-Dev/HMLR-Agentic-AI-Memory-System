================================================================================
TERMINAL OUTPUT FOR THIS TURN
================================================================================
Timestamp: 2025-11-28 22:59:17
Turn ID: turn_20251128_225913_080
================================================================================

   ğŸ“ Debug: User query logged to 01_user_query_20251128_225913_080.txt
   ğŸ¤– Using GPT-4.1-nano keywords for retrieval: ['HMLR']
   ğŸ”„ Active Span: span_20251128_225913_088974 (mentions hmlr)
   ğŸ§¹ Topic Shift Detected! Clearing sliding window for Tabula Rasa.
   ğŸ“ Debug: User query logged to 01_user_query_20251128_225913_080.txt
   ğŸ•¸ï¸  Lattice Retrieval: Fetching candidates...
ğŸ” Crawler: Searching with intent:
   Query Type: chat
   Keywords: ['HMLR']
   Primary Topics: ['Legal Services', 'Property Records']
ğŸ“‹ Found 0 active tasks
ğŸ“… Search range: ALL DAYS (unlimited)

ğŸ” VECTOR SEARCH (Primary Method):
   ğŸ” Ranked multi-keyword search: 'HMLR Legal Services Property Records...'
      Query keywords (5): ['HMLR', 'Legal', 'Services', 'Property', 'Records']
      Found 15 turns with keyword matches
   ğŸ¯ Top matches:
      1. score=7.32 | 3 kw matches | avg_sim=0.677 | hmlr, system...
      2. score=5.66 | 2 kw matches | avg_sim=0.440 | job, job...
      3. score=5.36 | 2 kw matches | avg_sim=0.440 | job, job...
   âœ… Returning 15 ranked results
   ğŸ”‘ Search query (keywords): 'HMLR Legal Services Property Records'
   âœ… Vector search successful, skipping keyword search

ğŸ“Š SEARCH RESULTS SUMMARY:
   Vector results: 15
   Keyword results: 0
   Total candidates: 15
âœ… Retrieved context: 15 snippets, 4 sources
      Found 15 candidates
   ğŸ›ï¸  The Governor: Filtering memories...
ğŸŒ Sending direct query to external API (model: gpt-4.1-nano)...
      Governor approved 2/15 memories
   ğŸ’§ Hydrator: Building context...
      Final context count: 2
   ğŸ“ Debug: Retrieved context logged to 02_retrieved_context_20251128_225913_080.txt
   ğŸ“ Debug: Sliding window logged to 03_sliding_window_20251128_225913_080.txt
   ğŸ’§ Building contextualized prompt...
      ğŸ“ Full prompt length: 2015 chars
      ğŸ“‹ Sliding window: 0 turns
   ğŸ“ Debug: Full prompt logged to 04_llm_prompt_20251128_225913_080.txt
   ğŸ¤– Calling LLM with context...
ğŸŒ Sending direct query to external API (model: gpt-4.1-mini)...
âœ… Chat response received
   ğŸ“Š Phase 4.1: Analyzing context usage...
      Citations found: 0
      Turn IDs used: set()
      Context efficiency: 0.0%

ğŸ’¬ Response: Yes, in the recent conversation history (from 2025-11-25), you mentioned HMLR as one of your active projects. HMLR stands for Hierarchical Memory & Lattice Retrieval, and it is described as a custom memory system using Retrieval-Augmented Generation (RAG) and 'The Governor'. This was noted alongside your Cognitive Lattice project and the Blue Sky business in your user profile glossary. If you want me to retrieve or act on any specific information related to HMLR, just let me know!
   ğŸ“ Debug: LLM response logged to 05_llm_response_20251128_225913_080.txt
   ğŸ“ Using GPT-4.1-nano keywords (1): ['HMLR']
   ğŸ·ï¸  Using GPT-4.1-nano topics (2): ['Legal Services', 'Property Records']
   ğŸ˜Š Detected affect: neutral
   ğŸ’¾ Logging turn to storage...
   ğŸ’¾ Logged turn t_20251128_225917_07d814... (seq=0) to day 2025-11-28
      ğŸ”‘ Saved 1 keywords with lineage
      ğŸ˜Š Saved affect with lineage
   ğŸ“‹ Adding to sliding window...
   ğŸ’¾ Saved sliding window state: 1 turns
   âœ… Turn logged: t_20251128_225917_07d814
   ğŸ”— Linked turn t_20251128_225917_07d814 to span span_20251128_225913_088974
   ğŸ” Generating embeddings from 1 LLM-extracted keywords...
   ğŸ” Generated 1 keyword embedding(s)
   ğŸ¯ Phase 4.3: Applying adaptive compression...
